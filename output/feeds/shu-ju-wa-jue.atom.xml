<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>nJcx's Blog - 数据挖掘</title><link href="http://www.njcx.bid/" rel="alternate"></link><link href="http://www.njcx.bid/feeds/shu-ju-wa-jue.atom.xml" rel="self"></link><id>http://www.njcx.bid/</id><updated>2017-05-20T13:20:00+03:00</updated><entry><title>K-means算法简介</title><link href="http://www.njcx.bid/posts/G9.html" rel="alternate"></link><published>2017-05-20T13:20:00+03:00</published><updated>2017-05-20T13:20:00+03:00</updated><author><name>nJcx</name></author><id>tag:www.njcx.bid,2017-05-20:/posts/G9.html</id><summary type="html">&lt;p&gt;K-means算法简介&lt;/p&gt;</summary><content type="html">&lt;h4&gt;问题&lt;/h4&gt;
&lt;p&gt;在图的左边有一些点，我们用肉眼可以看出来有四个点群，但是我们怎么通过计算机程序找出这几个点群来呢？于是就出现了我们的K-Means算法&lt;/p&gt;
&lt;p&gt;&lt;img alt="ml2" class="img-fluid" src="../images/K-Means.gif"/&gt;&lt;/p&gt;
&lt;h4&gt;算法概要&lt;/h4&gt;
&lt;p&gt;这个算法其实很简单，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img alt="ml2" class="img-fluid" src="../images/K-Means.jpg"/&gt;&lt;/p&gt;
&lt;p&gt;从上图中，我们可以看到，A, B, C, D, E 是五个在图中点。而灰色的点是我们的种子点，也就是我们用来找点群的点。有两个种子点，所以K=2。&lt;/p&gt;
&lt;p&gt;然后，K-Means的算法如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;随机在图中取K（这里K=2）个种子点。&lt;/li&gt;
&lt;li&gt;然后对图中的所有点求到这K个种子点的距离，假如点Pi离种子点Si最近，那么Pi属于Si点群。（上图中，我们可以看到A,B属于上面的种子点，C,D,E属于下面中部的种子点）&lt;/li&gt;
&lt;li&gt;接下来，我们要移动种子点到属于他的“点群”的中心。（见图上的第三步）&lt;/li&gt;
&lt;li&gt;然后重复第2）和第3）步，直到，种子点没有移动（我们可以看到图中的第四步上面的种子点聚合了A,B,C，下面的种子点聚合了D，E）。&lt;/li&gt;
&lt;li&gt;这个算法很简单，但是有些细节我要提一下，距离的公式。我重点想说一下“求点群中心的算法”&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="ml2" class="img-fluid" src="../images/4630.png"/&gt;
&lt;img alt="ml2" class="img-fluid" src="../images/选区003.png"/&gt;&lt;/p&gt;
&lt;h4&gt;K-Means ++ 算法&lt;/h4&gt;
&lt;p&gt;K-Means主要有两个最重大的缺陷——都和初始值有关：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;K 是事先给定的，这个 K 值的选定是非常难以估计的。很多时候，事先并不知道给定的数据集应该分成多少个类别才最合适。（ ISODATA 算法通过类的自动合并和分裂，得到较为合理的类型数目 K）&lt;/li&gt;
&lt;li&gt;K-Means算法需要用初始随机种子点来搞，这个随机种子点太重要，不同的随机种子点会有得到完全不同的结果。（K-Means++算法可以用来解决这个问题，其可以有效地选择初始点）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我在这里重点说一下 K-Means++算法步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1,先从我们的数据库随机挑个随机点当“种子点”。&lt;/li&gt;
&lt;li&gt;2,对于每个点，我们都计算其和最近的一个“种子点”的距离D(x)并保存在一个数组里，然后把这些距离加起来得到Sum(D(x))。&lt;/li&gt;
&lt;li&gt;3,然后，再取一个随机值，用权重的方式来取计算下一个“种子点”。这个算法的实现是，先取一个能落在Sum(D(x))中的随机值Random，然后用Random -= D(x)，直到其                          &amp;lt;=0，此时的点就是下一个“种子点”。&lt;/li&gt;
&lt;li&gt;4,重复第（2）和第（3）步直到所有的K个种子点都被选出来。&lt;/li&gt;
&lt;li&gt;进行K-Means算法。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="ml2" class="img-fluid" src="../images/40.png"/&gt;&lt;/p&gt;</content><category term="数据挖掘算法"></category></entry><entry><title>机器学习简介</title><link href="http://www.njcx.bid/posts/G6.html" rel="alternate"></link><published>2017-05-17T13:20:00+03:00</published><updated>2017-05-17T13:20:00+03:00</updated><author><name>nJcx</name></author><id>tag:www.njcx.bid,2017-05-17:/posts/G6.html</id><summary type="html">&lt;p&gt;机器学习简介&lt;/p&gt;</summary><content type="html">&lt;h4&gt;介绍&lt;/h4&gt;
&lt;p&gt;人类的学习按逻辑顺序可分为三个阶段：输入，整合，输出。人类的学习是一个人根据过往的经验，对一类问题形成某种认识或总结出一定的规律，然后利用这些知识来对新的问题下判断的过程。人类学习能力强，但记性差，反应慢，还容易坏。计算机虽呆，但容量大，计算快，还稳定.这就引出我们今天的主题了，机器学习。我们对机器学习下这样一个定义了：机器学习是指用某些算法指导计算机利用已知数据得出适当的模型，并利用此模型对新的情境给出判断的过程。机器学习的思想并不复杂，它仅仅是对人类生活中学习过程的一个模拟。这整个过程中，最关键的是数据.
&lt;img alt="ml1" class="img-fluid" src="../images/6_hd.jpg"/&gt;&lt;/p&gt;
&lt;h4&gt;开始&lt;/h4&gt;
&lt;p&gt;机器学习根据所处理数据种类的不同，可以分为有监督学习，无监督学习，半监督学习和强化学习等几种类型。所谓监督学习，就是说数据样本会告诉计算机在该情形下的正确输出结果，希望计算机能够在面对没有见过的输入样本时也给出靠谱的输出结果，从而达到预测未知的目的。根据输出结果是离散值还是连续值，监督学习可以分为分类问题和回归问题两大类。回归通常用来预测一个值，如预测房价、未来的天气情况等等，回归是对真实值（Real）的一种逼近预测。分类(classification)就是将实例数据划分到合适的分类中。分类问题是用于将事物打上一个标签，通常结果为离散值。分类并没有逼近的概念，最终正确结果只有一个，错误的就是错误的，不会有相近的概念。他们在文字、语音、图像识别，垃圾邮件分类与拦截，网页检索，股票预测等方面有着广泛应用。无监督学习，是指数据样本中没有给出正确的目标变量,希望推断出数据的一些内在结构，从数据中挖掘出目标变量，常见的例子有聚类，关联规则挖掘，离群点检测等等。&lt;/p&gt;
&lt;p&gt;&lt;img alt="ml1" class="img-fluid" src="../images/ml1.png"/&gt;&lt;/p&gt;
&lt;h4&gt;AI与机器学习,深度学习&lt;/h4&gt;
&lt;p&gt;AI即人工智能是一个很大的学科，主要含已下内容：计算机视觉，自然语言处理，认知和推理，机器人，博弈和伦理，机器学习。其中，深度学习本来是机器学习的子集，由于发展的足够庞大，已经独立成一个单独的主题了。这一部分内容又和传统的数据挖掘有着千丝万缕的关系，下面列出相关关系：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模式识别=机器学习&lt;/li&gt;
&lt;li&gt;数据挖掘=机器学习+数据库&lt;/li&gt;
&lt;li&gt;统计学习=机器学习&lt;/li&gt;
&lt;li&gt;计算机视觉=图像处理+机器学习&lt;/li&gt;
&lt;li&gt;语音识别=语音处理+机器学习&lt;/li&gt;
&lt;li&gt;自然语言处理=文本处理+机器学习&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;机器学习算法&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;监督学习包含算法：k-近邻算法、决策树、支持向量机、朴素贝叶斯算法、Logistic回归,线性回归、局部加权线性回归、Ridge回归、Lasso最小回归系数估计,随机森林(提高分类准确度),Adaboost(提高分类准确度)等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;非监督学习包含算法：K-均值,最大期望算法(EM)、DBSCAN,SVD(奇异值分解),PCA(主成因分析),Apriori算法,FP-Growth,隐马克夫模型(HMM)等。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(分类,回归,聚类,降维,关联分析)
&lt;img alt="mlx" class="img-fluid" src="../images/mlx.png"/&gt;&lt;/p&gt;
&lt;h4&gt;机器学习框架以及相关类库&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;scikit-learn&lt;/li&gt;
&lt;li&gt;pybrain&lt;/li&gt;
&lt;li&gt;milk&lt;/li&gt;
&lt;li&gt;orange&lt;/li&gt;
&lt;li&gt;bigml&lt;/li&gt;
&lt;li&gt;pyml&lt;/li&gt;
&lt;li&gt;mllib （spark，支持java，scala，Python）&lt;/li&gt;
&lt;li&gt;weka (java)&lt;/li&gt;
&lt;li&gt;mahout (java)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;深度学习主要算法以及相关类库&lt;/h4&gt;
&lt;p&gt;主要算法:CNN(卷积神经网络)、RNN(循环神经网络)、DNN(深度神经网络)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MXNet&lt;/li&gt;
&lt;li&gt;Caffe&lt;/li&gt;
&lt;li&gt;CNTK&lt;/li&gt;
&lt;li&gt;Neon&lt;/li&gt;
&lt;li&gt;TensorFlow&lt;/li&gt;
&lt;li&gt;Torch&lt;/li&gt;
&lt;li&gt;Theano&lt;/li&gt;
&lt;li&gt;Keras&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上述大部分深度学习类库都支持GPU加速,(Ubuntu16.04 + GTX 1080 TI + CUDA（目前9.0版，兼容性并不好)+ cuDNN（cuDNN是为DNN设计的CPU加速库）+CNMeM(合理分配显存)=深度学习标配环境&lt;/p&gt;</content><category term="ml"></category></entry></feed>